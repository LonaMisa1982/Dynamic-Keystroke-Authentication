{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92015ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from '../random_forest_model.pkl'...\n",
      "Loading new data from '../Keystrokes.csv'...\n",
      "Preprocessing data (applying to_numeric and dropping rows with errors)...\n",
      "Making 1 predictions...\n",
      "Saving results...\n",
      "\n",
      "--- Prediction Complete ---\n",
      "Results saved to 'keystroke_predictions.csv'\n",
      "\n",
      "Prediction counts:\n",
      "Prediction\n",
      "Imposter    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "MODEL_FILE = '../random_forest_model.pkl'\n",
    "\n",
    "NEW_DATA_FILE = '../Keystrokes.csv'\n",
    "\n",
    "OUTPUT_FILE = 'keystroke_predictions.csv'\n",
    "FEATURE_NAMES = [\n",
    "    'H.period', 'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i',\n",
    "    'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five',\n",
    "    'UD.e.five', 'H.five', 'DD.five.Shift.r', 'UD.five.Shift.r',\n",
    "    'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o', 'DD.o.a',\n",
    "    'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l', 'UD.n.l',\n",
    "    'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return'\n",
    "]\n",
    "\n",
    "def predict_new_data():\n",
    "    \"\"\"\n",
    "    Loads the saved model and predicts on a new, unlabeled CSV file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(MODEL_FILE):\n",
    "        print(f\"Error: Model file '{MODEL_FILE}' not found.\")\n",
    "        print(\"Please place your .pkl file in the same directory as this script.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(NEW_DATA_FILE):\n",
    "        print(f\"Error: New data file '{NEW_DATA_FILE}' not found.\")\n",
    "        print(f\"Please update the 'NEW_DATA_FILE' variable in this script to match your file's name.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading model from '{MODEL_FILE}'...\")\n",
    "    try:\n",
    "        with open(MODEL_FILE, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading new data from '{NEW_DATA_FILE}'...\")\n",
    "    try:\n",
    "        new_data = pd.read_csv(NEW_DATA_FILE, header=0) # Changed from header=1 to header=0\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    original_data_with_index = new_data.copy()\n",
    "    original_data_with_index['original_index'] = new_data.index\n",
    "\n",
    "    missing_cols = [col for col in FEATURE_NAMES if col not in new_data.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"\\nError: The new data file is missing required feature columns:\")\n",
    "        print(missing_cols)\n",
    "        return\n",
    "\n",
    "    print(\"Preprocessing data (applying to_numeric and dropping rows with errors)...\")\n",
    "\n",
    "    for feature in FEATURE_NAMES:\n",
    "        new_data[feature] = pd.to_numeric(new_data[feature], errors='coerce')\n",
    "\n",
    "    original_row_count = len(new_data)\n",
    "    new_data.dropna(subset=FEATURE_NAMES, inplace=True)\n",
    "    processed_row_count = len(new_data)\n",
    "\n",
    "    if original_row_count > processed_row_count:\n",
    "        print(f\"Warning: Dropped {original_row_count - processed_row_count} rows due to missing/invalid data.\")\n",
    "\n",
    "    if new_data.empty:\n",
    "        print(\"Error: No valid data left to predict after preprocessing.\")\n",
    "        return\n",
    "\n",
    "    X_predict = new_data[FEATURE_NAMES]\n",
    "\n",
    "    print(f\"Making {len(X_predict)} predictions...\")\n",
    "    try:\n",
    "        predictions = model.predict(X_predict)\n",
    "        probabilities = model.predict_proba(X_predict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 5. Save Results ---\n",
    "    print(\"Saving results...\")\n",
    "\n",
    "    # Add prediction results to the processed dataframe\n",
    "    new_data['Prediction'] = predictions\n",
    "    new_data['Probability_Genuine'] = probabilities[:, 0]\n",
    "    new_data['Probability_Imposter'] = probabilities[:, 1]\n",
    "\n",
    "    output_df = pd.merge(\n",
    "        original_data_with_index,\n",
    "        new_data[['Prediction', 'Probability_Genuine', 'Probability_Imposter']],\n",
    "        left_on='original_index',\n",
    "        right_index=True,\n",
    "        how='right' # Use 'right' to keep only the processed/predicted rows\n",
    "    ).drop(columns=['original_index'])\n",
    "\n",
    "\n",
    "    output_df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(\"\\n--- Prediction Complete ---\")\n",
    "    print(f\"Results saved to '{OUTPUT_FILE}'\")\n",
    "    print(\"\\nPrediction counts:\")\n",
    "    print(output_df['Prediction'].value_counts(dropna=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    predict_new_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
